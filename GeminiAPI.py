import random
import json
import requests
from api_secrets import gemini_api_key
import sqlite3
# Name: Kush Patel
# Project Description: This program generates a markdown resume by combining a personal description with
#                      a randomly selected job description from rapid_jobs2.json. The markdown resume is
#                      generated by prompting the Gemini AI model to create a markdown resume based on this information.

#TODO: python -m pytest tests/*

# Function to get a random job listing from the JSON file
def get_random_json_object():
    with open('rapid_jobs2.json', 'r') as f:
        json_objects = []
        for line in f:
            # Read each line in rapid_jobs2.json file as a JSON object
            json_objects.append(json.loads(line))
        # Select a random section from the JSON list
        random_job_section = random.choice(json_objects)
        # Select a random job within the chosen section
        random_job = random.choice(random_job_section)
    return random_job

#Function to get all json objects
def get_all_json_objects():
    json_objects = []
    with open('rapid_jobs2.json', 'r') as f:
        for line in f:
            # Read each line in rapid_jobs2.json file as a JSON object
            objs_array =json.loads(line)
            for obj in objs_array:
                json_objects.append(obj)

    with open('rapid_job1.json', 'r') as f:
        for line in f:
            # Read each line in rapid_jobs2.json file as a JSON object
            json_objects.append(json.loads(line))
    #with open('output.txt', 'w') as f:
    #    f.write(json.dumps(json_objects[1400], indent=4))
    return json_objects


#Connect to database
def connect_job_database(cursor, conn):
    # Read the SQL file
    with open("job_database.sql", "r") as file:
        sql_script = file.read()

    # Execute the SQL script (AI helped find the executescript() function)
    cursor.executescript(sql_script)
    # Commit changes
    conn.commit()

# Store job_json into job table
def insert_to_job(conn, cursor, job_info):
    job_id = job_info.get("id")

    # Check if job_id already exists
    cursor.execute("SELECT COUNT(*) FROM jobs WHERE id = ?", (job_id,))
    exists = cursor.fetchone()[0]

    if exists:
        print(f"Skipping job {job_id}, already exists.")
        return  # Skip inserting duplicate

    #There are two different date posted in the json files
    #There is date_posted and datePosted, this just fixes that issue
    date_posted = job_info.get("date_posted", None)
    date_posted2 = job_info.get("datePosted", None)
    date = ""
    if date_posted is not None:
        date = date_posted
    else:
        date = date_posted2

    cursor.execute("""
        Insert INTO jobs (id, site, job_url, job_url_direct, title, company_name, company_industry, company_url, company_url_direct, company_addresses, company_num_employees, company_revenue, company_description, logo_photo_url, banner_photo_url, ceo_name, ceo_photo_url, location, job_type, date_posted, salary_source, interval, min_amount, max_amount, currency, is_remote, job_level, job_function, listing_type, emails, description, employment_type, salary_range, image) 
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? ,?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?);
    """, (job_info.get("id"),
        job_info.get("site", None),
        job_info.get("job_url", None),
        job_info.get("job_url_direct", None),
        job_info.get("title", None),
        job_info.get("company_name", None),
        job_info.get("company_industry", None),
        job_info.get("company_url", None),
        job_info.get("company_url_direct", None),
        job_info.get("company_addresses", None),  # Use company ID as foreign key
        job_info.get("company_num_employees", None),
        job_info.get("company_revenue", None),
        job_info.get("company_description", None),
        job_info.get("logo_photo_url", None),
        job_info.get("banner_photo_url", None),
        job_info.get("ceo_name", None),
        job_info.get("ceo_photo_url", None),
        job_info.get("location", None),
        job_info.get("job_type", None),
        date,
        job_info.get("salary_source", None),
        job_info.get("interval", None),
        job_info.get("min_amount", None),
        job_info.get("max_amount", None),
        job_info.get("currency", None),
        job_info.get("is_remote", None),
        job_info.get("job_level", None),
        job_info.get("job_function", None),
        job_info.get("listing_type", None),
        job_info.get("emails", None),
        job_info.get("description", None),
        job_info.get("employment_type", None),
        job_info.get("salary_range", None),
        job_info.get("image", None))
    )
    conn.commit()

# Function to insert job providers
def insert_to_job_provider(conn, cursor, job_id, providers):
    for provider in providers:
        cursor.execute("""
            INSERT INTO job_providers (job_id, provider_name, provider_url)
            VALUES (?, ?, ?)
        """, (job_id, provider.get('jobProvider', None), provider.get('url', None)))
    conn.commit()




def main():
    # Get the API key from the api_secrets file to access Google's Gemini AI model
    key = gemini_api_key
    # Using the random_json_object(), get a random job and then extract the job description from the job.
    job_json_random = get_random_json_object()
    job_description = job_json_random["description"]

    # Connect to the SQLite database (or create one if it doesn't exist)
    conn = sqlite3.connect("Jobs_Database.db")
    cursor = conn.cursor()
    #Connect the Jobs_Database.db
    connect_job_database(cursor, conn)
    all_json_obj = get_all_json_objects()
    for i, obj in enumerate(all_json_obj):
        #Insert json info in database
        insert_to_job(conn, cursor, obj)
        insert_to_job_provider(conn, cursor, obj['id'], obj.get('jobProviders', []))
    print("Data successfully inserted!")
    conn.close()

    # Personal information to be included in the resume
    personal_info = ("My name is Kush Patel. I am a computer science major studying at Bridgewater State University (BSU),"
                     " I am driven by a desire to innovate and problem solve. I am graduating from the BSU on May, 2025. "
                     "Some important courses I have completed at BSU are Web Application Development, Computer Networks, "
                     "Software Engineering, Cloud Computing, Introduction Database systems, Introduction to A.I., and "
                     "Unix/Linux System Admin.I was awarded Dr. Linda Wilkens and Dr. Glenn Pavlicek Scholarship at BSU in "
                     "recognition of my academic achievements such as a 4.0 major GPA. I am from East Greenwich, Road Island "
                     "but I currently live in Fairhaven, Massachusetts. Some programing languages that I am proficient at are"
                     " Python, Java, Swift, and JavaScript. I also MySQL from my database system course. Currently, I am "
                     "developing a bank statement processing application that efficiently converts bank statements into Excel"
                     " spreadsheets. With a positive attitude and a relentless motivation to learn, I'm eager to take on new "
                     "challenges and expand my expertise. Additionally, along with my current project, I am also doing a "
                     "research internship at Bridgewater State University in which I am developing a program that can recognize"
                     " a table in an image and convert it to an excel table. Some tools that I know are Git, JetBrain IDEs, "
                     "Xcode, and Vscode. My hobbies are playing basketball, cricket, and programing.")

    # Prepare the API request payload for Google's Gemini AI model
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={key}"
    headers = {'content-type': 'application/json'}
    data = {
        "contents": [{
            "parts": [{"text": f"Remember my Personal Information: {personal_info} \n Remember the Job description: "
                               f"{job_description} \n Now create a resume in markdown format that will be designed from "
                               f"my personal information, using keywords from job description that I provided"}]
        }]
    }

    # Send a post request to the Gemini API
    response = requests.post(url, headers=headers, json=data)
    response_json = response.json()

    # Extract the generated markdown resume from the API response
    marked_resume = response_json["candidates"][0]["content"]["parts"][0]["text"]

    # Save the generated resume to a markdown file
    new_file_name = "Marked_Resume.md"
    with open(new_file_name, 'w') as f:
        f.write(marked_resume)

main()

